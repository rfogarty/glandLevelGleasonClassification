# Gland-Level Gleason Classification
This publicly available repository contains Python/TensorFlow code to train a VGG16-based
CNN to discriminate prostate pathology patches on Gleason Patterns.

## Licensing
Please see LICENSE file for restrictions building upon this code and/or especially
for commercial purposes.

This code has 2 small routines that were tailored from Snapshot-Ensemble by Jason Brownlee
(https://machinelearningmastery.com/snapshot-ensemble-deep-learning-neural-network/)
and a file listing utility from imutils originally from Adrian Rosebrook
(https://github.com/PyImageSearch/imutils). Both of these routines have been heavily 
modified and made more robust for my use. However, please seek their websites for 
licensing of their code, or remove the appropriate code blocks if their licensing terms 
are not agreeable/possible in your case.

## Installation
This code was last tested on Python 3.8.10 and TensorFlow 2.9.1 on an NVidia DGX platform
with A100 hardware. A GPU accelerator (such as NVidia Quadro A6000, RTX 3090, or A100)
and appropriately tuned libraries are strongly encouraged.

The following particular set of libraries was used to run the included Python/TF code:

     keras                         2.9.0
     packaging                     21.3
     pandas                        1.4.3
     numpy                         1.23.2
     nvidia-dali-cuda110           1.9.0
     nvidia-dali-tf-plugin-cuda110 1.9.0
     opencv-python-headless        4.6.0.66
     scikit-image                  0.19.3
     scikit-learn                  0.24.0
     tensorflow                    2.9.1
     tensorflow-gpu                2.9.1

Please use a virtual environment (Docker, Singularity, Anaconda) to load the appropriate
libraries for your platform. A Docker container derived from NVidia NGC was used for our tests.
Additional libraries were installed with pip from our Dockerfile.

## Execution
The provided code performs training of a Convolutional Neural Network based on the VGG-16
architecture.

### Constructing data set
To run the program, firstly a data directory must be created with patches of histopathological
prostate biopsy images. For our research patches were generated from a proprietary data cohort 
(that is not available for distribution) and from Kaggle PANDA, which is publicly available
(https://www.kaggle.com/c/prostate-cancer-grade-assessment). Note, the Kaggle PANDA Radboud 
data was used in our tests (but not Karolinska data).

Kaggle patches were generated by Otsu binarizing the images, then using an 800x800 sliding 
window (at 25% overlap) to select images with at least 75% Otsu-binarized foreground (biopsy), 
selecting images that contained at least 10% of label mask (not background or stroma), and 
labels that were 95% purely of one Gleason Pattern rating (benign, GS3, GS4, or GS5). Note
then, that 3 different thresholding tests take place to select appropriate patches.
Kaggle images were downsampled from 800x800 to 400x400 pixels before training on CNN. 

The directory containing the data collection should have the following organization:

     - .../DataDir/
         | - GS0/*
             |- ID0-patch0.png
             |- ID0-patch1.png
             |- ID0-patch2.png
             |- ...
         | - GS3/ ...
         | - GS4/ ...
         | - GS5/ ...
         | - trainging_set.files
         | - validation_set0.files # subset/fold 0 of training_set.files
             ...
         | - validation_set9.files # subset/fold 9 of training_set.files

* Note classes are determined by what directory patch files are located.

### Tweaking dataParameters.py
A file called dataParameters.py is provided that configures where data files are located,
where training and validation file listings are located, how to construct labels from 
each filename or path, and several other configurable pieces. Once configured for a particular 
dataset, these settings are unlikely to change. Many other hyper-parameter settings are 
available to modify from the commandline as demonstrated next.

### Training
The file python/train_multi.py is the main entry point to train the CNN/DL network. Once 
a virtual environment is loaded with paths to the appropriate libraries (as mentioned above),
simply call:

     $ cd python/
     $ gpus=(0) # For single GPU or gpus=(1 3 5 6), e.g. for training across multiple GPUs
     # Most common arugments to set: see argument.py for other options.
     $ extra_args=( \
            -g ${gpus[@]} \
            -b 90 \
            -P 3 \
            -c 29 \
            -l 0.05) 
     # where: -b=batch size, 
     #        -P=pools - num pools to randomly split data into (upon each epoch train)
     #        -c=cycle - num epochs for cosine annealing of learning rate
     #        -l=learningRate - max learning rate
     $ split=0 # through however many validation_set${split}.files sets are available.
     $ time python train_multi.py -s "${split}" ${extra_args[@]} 2>&1 | tee trainingLog${split}.txt

## Fine-Tuning and Testing
Entry points for testing with an independent set and collecting statistics are not provided
in the repository. However, model.py does have routines to construct a network for fine-tuning
(based on prior coarse-tuned weight files) and performing inference tests on independent sets.

